{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ce99528",
   "metadata": {},
   "source": [
    "## Working with Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dae80fa",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7addb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042ee1b8",
   "metadata": {},
   "source": [
    "## SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f954897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccb69c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, to_timestamp, lit, col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1605a3a8",
   "metadata": {},
   "source": [
    "**2019-12-25 13:30:00**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0002c124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          Christmas|\n",
      "+-------------------+\n",
      "|2019-12-25 13:30:00|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [('2019-12-25 13:30:00',)],\n",
    "    ['Christmas'])\n",
    "\n",
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c872271b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+--------------------------------------------+\n",
      "|to_date(Christmas, yyyy-MM-dd HH:mm:ss)|to_timestamp(Christmas, yyyy-MM-dd HH:mm:ss)|\n",
      "+---------------------------------------+--------------------------------------------+\n",
      "|                             2019-12-25|                         2019-12-25 13:30:00|\n",
      "+---------------------------------------+--------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(to_date(col('Christmas'), 'yyyy-MM-dd HH:mm:ss'), \n",
    "          to_timestamp(col('Christmas'), 'yyyy-MM-dd HH:mm:ss')).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e82da6",
   "metadata": {},
   "source": [
    "**25/Dec/2019 13:30:00**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a0e16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           Christmas|\n",
      "+--------------------+\n",
      "|25/Dec/2019 13:30:00|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([('25/Dec/2019 13:30:00',)], ['Christmas'])\n",
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "445fa861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+---------------------------------------------+\n",
      "|to_date(Christmas, dd/MMM/yyyy HH:mm:ss)|to_timestamp(Christmas, dd/MMM/yyyy HH:mm:ss)|\n",
      "+----------------------------------------+---------------------------------------------+\n",
      "|                              2019-12-25|                          2019-12-25 13:30:00|\n",
      "+----------------------------------------+---------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(to_date(col('Christmas'), 'dd/MMM/yyyy HH:mm:ss'), \n",
    "          to_timestamp(col('Christmas'), 'dd/MMM/yyyy HH:mm:ss')).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662f4265",
   "metadata": {},
   "source": [
    "**12/25/2019 01:30:00 PM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81e207e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|Christmas             |\n",
      "+----------------------+\n",
      "|12/25/2019 01:30:00 PM|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([('12/25/2019 01:30:00 PM',)], ['Christmas'])\n",
    "df.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7769e5eb",
   "metadata": {},
   "source": [
    "## Changes in Datetime patterns in spark 3\n",
    "\n",
    "To continue using the datetime patterns in spark 2, use `spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")` otherwise for spark 3 datetime patterns use only one letter as shown below. For more on datetime patterns changes in spark 3, please refer to the [docs](https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b68d6f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+--------------------------------------+\n",
      "|to_date(Christmas, M/d/y h:m:s a)|to_timestamp(Christmas, M/d/y h:m:s a)|\n",
      "+---------------------------------+--------------------------------------+\n",
      "|                       2019-12-25|                   2019-12-25 13:30:00|\n",
      "+---------------------------------+--------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(to_date(col('Christmas'), 'M/d/y h:m:s a'),\n",
    "         to_timestamp(col('Christmas'), 'M/d/y h:m:s a')).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61337227",
   "metadata": {},
   "source": [
    "## Display\n",
    "\n",
    "Set the browser to display scrollable dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "612292c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre {white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre {white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8f28c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------------------+---------------------+----+------------+-----------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+----------------------+------------+-------------+-----------------------------+\n",
      "|ID      |Case Number|Date                  |Block                |IUCR|Primary Type|Description            |Location Description|Arrest|Domestic|Beat|District|Ward|Community Area|FBI Code|X Coordinate|Y Coordinate|Year|Updated On            |Latitude    |Longitude    |Location                     |\n",
      "+--------+-----------+----------------------+---------------------+----+------------+-----------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+----------------------+------------+-------------+-----------------------------+\n",
      "|10224738|HY411648   |09/05/2015 01:30:00 PM|043XX S WOOD ST      |0486|BATTERY     |DOMESTIC BATTERY SIMPLE|RESIDENCE           |false |true    |0924|009     |12  |61            |08B     |1165074     |1875917     |2015|02/10/2018 03:50:01 PM|41.815117282|-87.669999562|(41.815117282, -87.669999562)|\n",
      "|10224739|HY411615   |09/04/2015 11:30:00 AM|008XX N CENTRAL AVE  |0870|THEFT       |POCKET-PICKING         |CTA BUS             |false |false   |1511|015     |29  |25            |06      |1138875     |1904869     |2015|02/10/2018 03:50:01 PM|41.895080471|-87.765400451|(41.895080471, -87.765400451)|\n",
      "|11646166|JC213529   |09/01/2018 12:01:00 AM|082XX S INGLESIDE AVE|0810|THEFT       |OVER $500              |RESIDENCE           |false |true    |0631|006     |8   |44            |06      |null        |null        |2018|04/06/2019 04:04:43 PM|null        |null         |null                         |\n",
      "|10224740|HY411595   |09/05/2015 12:45:00 PM|035XX W BARRY AVE    |2023|NARCOTICS   |POSS: HEROIN(BRN/TAN)  |SIDEWALK            |true  |false   |1412|014     |35  |21            |18      |1152037     |1920384     |2015|02/10/2018 03:50:01 PM|41.937405765|-87.716649687|(41.937405765, -87.716649687)|\n",
      "|10224741|HY411610   |09/05/2015 01:00:00 PM|0000X N LARAMIE AVE  |0560|ASSAULT     |SIMPLE                 |APARTMENT           |false |true    |1522|015     |28  |25            |08A     |1141706     |1900086     |2015|02/10/2018 03:50:01 PM|41.881903443|-87.755121152|(41.881903443, -87.755121152)|\n",
      "+--------+-----------+----------------------+---------------------+----+------------+-----------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+----------------------+------------+-------------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_path = 'file:///' + os.getcwd() + '/data'\n",
    "\n",
    "file_path = data_path + '/reported-crimes.csv'\n",
    "\n",
    "crimes_df = (\n",
    "    spark.read\n",
    "    .csv(file_path, header=True)\n",
    ")\n",
    "\n",
    "crimes_df.show(5, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
