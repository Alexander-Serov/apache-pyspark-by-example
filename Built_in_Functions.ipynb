{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ec6ffa4",
   "metadata": {},
   "source": [
    "# Built-in Functions\n",
    "\n",
    "PySpark comes with built-in functions which are available in the `pyspark.sql.functions` library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498ec155",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1248bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb098d0",
   "metadata": {},
   "source": [
    "## SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8faf37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "             .builder\n",
    "             .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0087005e",
   "metadata": {},
   "source": [
    "## Display\n",
    "\n",
    "To allow the browser to display scrollable dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2dc877d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre {white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre {white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3206da",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3d339cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------------------+--------------------+----+------------+--------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+--------------------+------------+-------------+--------------------+\n",
      "|      ID|Case Number|               Date|               Block|IUCR|Primary Type|         Description|Location Description|Arrest|Domestic|Beat|District|Ward|Community Area|FBI Code|X Coordinate|Y Coordinate|Year|          Updated On|    Latitude|    Longitude|            Location|\n",
      "+--------+-----------+-------------------+--------------------+----+------------+--------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+--------------------+------------+-------------+--------------------+\n",
      "|10224738|   HY411648|2015-09-05 13:30:00|     043XX S WOOD ST|0486|     BATTERY|DOMESTIC BATTERY ...|           RESIDENCE| false|    true|0924|     009|  12|            61|     08B|     1165074|     1875917|2015|02/10/2018 03:50:...|41.815117282|-87.669999562|(41.815117282, -8...|\n",
      "|10224739|   HY411615|2015-09-04 11:30:00| 008XX N CENTRAL AVE|0870|       THEFT|      POCKET-PICKING|             CTA BUS| false|   false|1511|     015|  29|            25|      06|     1138875|     1904869|2015|02/10/2018 03:50:...|41.895080471|-87.765400451|(41.895080471, -8...|\n",
      "|11646166|   JC213529|2018-09-01 00:01:00|082XX S INGLESIDE...|0810|       THEFT|           OVER $500|           RESIDENCE| false|    true|0631|     006|   8|            44|      06|        null|        null|2018|04/06/2019 04:04:...|        null|         null|                null|\n",
      "|10224740|   HY411595|2015-09-05 12:45:00|   035XX W BARRY AVE|2023|   NARCOTICS|POSS: HEROIN(BRN/...|            SIDEWALK|  true|   false|1412|     014|  35|            21|      18|     1152037|     1920384|2015|02/10/2018 03:50:...|41.937405765|-87.716649687|(41.937405765, -8...|\n",
      "|10224741|   HY411610|2015-09-05 13:00:00| 0000X N LARAMIE AVE|0560|     ASSAULT|              SIMPLE|           APARTMENT| false|    true|1522|     015|  28|            25|     08A|     1141706|     1900086|2015|02/10/2018 03:50:...|41.881903443|-87.755121152|(41.881903443, -8...|\n",
      "+--------+-----------+-------------------+--------------------+----+------------+--------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+--------------------+------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql.functions import to_timestamp, col, lit\n",
    "\n",
    "data_path = 'file:///' + os.getcwd() + '/data'\n",
    "\n",
    "file_path = data_path + '/reported-crimes.csv'\n",
    "\n",
    "crimes_df = (spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .csv(file_path)\n",
    "    .withColumn(\"Date\", to_timestamp(col(\"Date\"), \"MM/dd/yyyy hh:mm:ss a\"))\n",
    "    .filter(col(\"Date\") <= lit(\"2018-11-11\"))\n",
    ")\n",
    "\n",
    "crimes_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9afd5b2",
   "metadata": {},
   "source": [
    "## Built-in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5c9785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c20cbd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Column', 'DataFrame', 'DataType', 'PandasUDFType', 'PythonEvalType', 'SparkContext', 'StringType', 'UserDefinedFunction', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_create_column_from_literal', '_create_lambda', '_create_udf', '_get_get_jvm_function', '_get_lambda_parameters', '_invoke_binary_math_function', '_invoke_function', '_invoke_function_over_column', '_invoke_higher_order_function', '_options_to_str', '_test', '_to_java_column', '_to_seq', '_unresolved_named_lambda_variable', 'abs', 'acos', 'acosh', 'add_months', 'aggregate', 'approxCountDistinct', 'approx_count_distinct', 'array', 'array_contains', 'array_distinct', 'array_except', 'array_intersect', 'array_join', 'array_max', 'array_min', 'array_position', 'array_remove', 'array_repeat', 'array_sort', 'array_union', 'arrays_overlap', 'arrays_zip', 'asc', 'asc_nulls_first', 'asc_nulls_last', 'ascii', 'asin', 'asinh', 'assert_true', 'atan', 'atan2', 'atanh', 'avg', 'base64', 'bin', 'bitwiseNOT', 'broadcast', 'bround', 'bucket', 'cbrt', 'ceil', 'coalesce', 'col', 'collect_list', 'collect_set', 'column', 'concat', 'concat_ws', 'conv', 'corr', 'cos', 'cosh', 'count', 'countDistinct', 'covar_pop', 'covar_samp', 'crc32', 'create_map', 'cume_dist', 'current_date', 'current_timestamp', 'date_add', 'date_format', 'date_sub', 'date_trunc', 'datediff', 'dayofmonth', 'dayofweek', 'dayofyear', 'days', 'decode', 'degrees', 'dense_rank', 'desc', 'desc_nulls_first', 'desc_nulls_last', 'element_at', 'encode', 'exists', 'exp', 'explode', 'explode_outer', 'expm1', 'expr', 'factorial', 'filter', 'first', 'flatten', 'floor', 'forall', 'format_number', 'format_string', 'from_csv', 'from_json', 'from_unixtime', 'from_utc_timestamp', 'functools', 'get_json_object', 'greatest', 'grouping', 'grouping_id', 'hash', 'hex', 'hour', 'hours', 'hypot', 'initcap', 'input_file_name', 'instr', 'isnan', 'isnull', 'json_tuple', 'kurtosis', 'lag', 'last', 'last_day', 'lead', 'least', 'length', 'levenshtein', 'lit', 'locate', 'log', 'log10', 'log1p', 'log2', 'lower', 'lpad', 'ltrim', 'map_concat', 'map_entries', 'map_filter', 'map_from_arrays', 'map_from_entries', 'map_keys', 'map_values', 'map_zip_with', 'max', 'md5', 'mean', 'min', 'minute', 'monotonically_increasing_id', 'month', 'months', 'months_between', 'nanvl', 'next_day', 'nth_value', 'ntile', 'overlay', 'pandas_udf', 'percent_rank', 'percentile_approx', 'posexplode', 'posexplode_outer', 'pow', 'quarter', 'radians', 'raise_error', 'rand', 'randn', 'rank', 'regexp_extract', 'regexp_replace', 'repeat', 'reverse', 'rint', 'round', 'row_number', 'rpad', 'rtrim', 'schema_of_csv', 'schema_of_json', 'second', 'sequence', 'sha1', 'sha2', 'shiftLeft', 'shiftRight', 'shiftRightUnsigned', 'shuffle', 'signum', 'sin', 'since', 'sinh', 'size', 'skewness', 'slice', 'sort_array', 'soundex', 'spark_partition_id', 'split', 'sqrt', 'stddev', 'stddev_pop', 'stddev_samp', 'struct', 'substring', 'substring_index', 'sum', 'sumDistinct', 'sys', 'tan', 'tanh', 'timestamp_seconds', 'toDegrees', 'toRadians', 'to_csv', 'to_date', 'to_json', 'to_str', 'to_timestamp', 'to_utc_timestamp', 'transform', 'transform_keys', 'transform_values', 'translate', 'trim', 'trunc', 'udf', 'unbase64', 'unhex', 'unix_timestamp', 'upper', 'var_pop', 'var_samp', 'variance', 'warnings', 'weekofyear', 'when', 'window', 'xxhash64', 'year', 'years', 'zip_with']\n"
     ]
    }
   ],
   "source": [
    "print(dir(functions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b027d25",
   "metadata": {},
   "source": [
    "## String functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6c9151",
   "metadata": {},
   "source": [
    "**Display the Primary Type column in lower and upper characters, and the first 4 characters of the column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e409008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower, upper, substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35438ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Case Number: string (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Block: string (nullable = true)\n",
      " |-- IUCR: string (nullable = true)\n",
      " |-- Primary Type: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Location Description: string (nullable = true)\n",
      " |-- Arrest: string (nullable = true)\n",
      " |-- Domestic: string (nullable = true)\n",
      " |-- Beat: string (nullable = true)\n",
      " |-- District: string (nullable = true)\n",
      " |-- Ward: string (nullable = true)\n",
      " |-- Community Area: string (nullable = true)\n",
      " |-- FBI Code: string (nullable = true)\n",
      " |-- X Coordinate: string (nullable = true)\n",
      " |-- Y Coordinate: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Updated On: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crimes_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e24018a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----------------------------+\n",
      "|lower(Primary Type)|upper(Primary Type)|substring(Primary Type, 1, 4)|\n",
      "+-------------------+-------------------+-----------------------------+\n",
      "|            battery|            BATTERY|                         BATT|\n",
      "|              theft|              THEFT|                         THEF|\n",
      "|              theft|              THEFT|                         THEF|\n",
      "|          narcotics|          NARCOTICS|                         NARC|\n",
      "|            assault|            ASSAULT|                         ASSA|\n",
      "+-------------------+-------------------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crimes_df.select(\n",
    "    lower(col('Primary Type')), \n",
    "    upper(col('Primary Type')), \n",
    "    substring(col('Primary Type'), 1, 4)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae2ad39",
   "metadata": {},
   "source": [
    "## Numeric functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16062a2",
   "metadata": {},
   "source": [
    "**Show the oldest date and the most recent date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "103b91f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00837a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:================================================>        (12 + 2) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|          min(Date)|          max(Date)|\n",
      "+-------------------+-------------------+\n",
      "|2001-01-01 00:00:00|2018-11-11 00:00:00|\n",
      "+-------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "crimes_df.select(min(col('Date')), max(col('Date'))).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd5b448",
   "metadata": {},
   "source": [
    "## Date\n",
    "\n",
    "**What is 3 days earlier than the oldest date and 3 days later than the most recent date?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02e5245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_add, date_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bca79e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:========================================>                (10 + 4) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+----------------------+\n",
      "|date_sub(min(Date), 3)|date_add(max(Date), 3)|\n",
      "+----------------------+----------------------+\n",
      "|            2000-12-29|            2018-11-14|\n",
      "+----------------------+----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 5:============================================>            (11 + 3) / 14]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "crimes_df.select(date_sub(min(col('Date')), 3), date_add(max(col('Date')), 3)).show(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
